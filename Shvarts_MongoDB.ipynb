{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import xmltodict \n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer as rt\n",
    "from bson.son import SON\n",
    "import pprint\n",
    "\n",
    "import pymongo\n",
    "from pymongo import TEXT\n",
    "from bson import ObjectId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание списка с XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_60 = '/Users/liliyarodicheva/Documents/GitHub/Elena_Shvarts/TEI/60'\n",
    "path_ZT = '/Users/liliyarodicheva/Documents/GitHub/Elena_Shvarts/TEI/Zelenaya_tetrad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_of_xml_from_dir(path): #функция, которая наши xml-файлы из директории читает и кладет в список\n",
    "    shvarts_xml= []\n",
    "    for i, file in enumerate(os.listdir(path)):\n",
    "        if file.endswith ('.xml'):\n",
    "            fullname = os.path.join(path, file)\n",
    "            with open(fullname, encoding='utf8') as xml_file:\n",
    "                xml = xml_file.read()\n",
    "                xml = re.sub('/text>\\n</TEI>', '/text>\\n<ID>'+str(i)+'</ID><file>'+file+'</file></TEI>\\n', xml)\n",
    "                xml = re.sub('<fileDesc>\\n', '<fileDesc>\\n<root></root>', xml)\n",
    "                shvarts_xml.append(xml)\n",
    "                xml_file.close() \n",
    "        \n",
    "    return shvarts_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#применяем нашу функцию по доставанию XML к директории, в которой лежат тексты 60-х годов\n",
    "shvarts_60_xml = create_list_of_xml_from_dir(path_60)\n",
    "shvarts_ZT_xml = create_list_of_xml_from_dir(path_ZT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение к базе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Пока что начинаем с того, что дропаем нашу базу данных'''\n",
    "client = pymongo.MongoClient('localhost', 27017) #подключаемся к MongoDB\n",
    "db = client['admin'] #создаем курсор для конкретной базы/контейнера\n",
    "db\n",
    "db['Shvarts_60'].drop()#поскольку мы постоянно пробуем и терять нам нечего, дропаем базу прям сразу же\n",
    "db['Shvarts_70'].drop()\n",
    "db['Shvarts_ZT'].drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_60 = db[\"Shvarts_60\"] #создаем внутри базы коллекции, где у нас лежат тексты/леммы/токены/строки за 60-е годы\n",
    "collection_70 = db.Shvarts_70\n",
    "collection_ZT = db.Shvarts_ZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сочинения, том 5. С.233 \n"
     ]
    }
   ],
   "source": [
    "example = \"<publisher>Сочинения, том 5. С.233 <date type='publishing'>2013</date></publisher>\"\n",
    "example = bs(example, 'xml')\n",
    "example = example.find('publisher').next_element\n",
    "# example = example.next_element\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Получаем данные по xml в виде json/словаря (как в тетрадке), а заодно кладем все в базу (операция Create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Создаем класс, как в примере с N+1 и все кладем в него, \n",
    "на выходе у нас данные не только в виде строк, но и в виде чисел'''\n",
    "\n",
    "class Shvarts_poems: \n",
    "    def __init__(self):\n",
    "        self.title=\"\"\n",
    "        self.root=\"\"\n",
    "        self.author=\"\"\n",
    "        self.editors=\"\"\n",
    "        self.publishers=\"\"\n",
    "        self.edition=\"\"\n",
    "        self.date_published=\"\"\n",
    "        self.date_written=\"\"\n",
    "        self.text=\"\"\n",
    "        self.ID=\"\"\n",
    "        self.file=\"\"\n",
    "        self.root=\"\"\n",
    "        self.children=\"\"\n",
    "\n",
    "def getPoemInfoShvarts(text):\n",
    "    text = re.sub('publishing', 'published', text)\n",
    "    text = re.sub('Издатели:', '', text)\n",
    "    text = re.sub('Редакторы:', '', text)\n",
    "    soup = bs(text, 'xml')\n",
    "    \n",
    "    poem=Shvarts_poems()\n",
    "    \n",
    "    poem.title = soup.find('title').text\n",
    "    poem.author = soup.find('author').text\n",
    "    \n",
    "    \n",
    "    poem.editors = ''\n",
    "    poem.publishers = ''\n",
    "    for i, resp in enumerate(soup.find_all('respStmt')):\n",
    "        if i == 0:\n",
    "            poem.editors += resp.text\n",
    "        if i == 1:\n",
    "            poem.publishers += resp.text       \n",
    "    poem.editors = re.sub('\\s+', ' ', poem.editors)\n",
    "    poem.publishers = re.sub('\\s+', ' ', poem.publishers)\n",
    "    \n",
    "    \n",
    "    poem.edition = soup.find('publisher').next_element\n",
    "    poem.edition = re.sub('\\s+', ' ', poem.edition)\n",
    "    \n",
    "    \n",
    "    poem.date_published = soup.find('date', {'type':'published'}).text\n",
    "    if poem.date_published is not None:\n",
    "        poem.date_published = int(poem.date_published)\n",
    "     \n",
    "    \n",
    "    poem.date_written = soup.find('date', {'type':'written'}).text\n",
    "    if poem.date_written in ('', ' '):\n",
    "        poem.date_written = None\n",
    "    elif poem.date_written is not None:\n",
    "        poem.date_written = int(poem.date_written)\n",
    "        \n",
    "    poem.ID = soup.find('ID').text\n",
    "    if poem.ID is not None:\n",
    "        poem.ID = int(poem.ID)\n",
    "        \n",
    "    poem.file = soup.find('file').text\n",
    "    \n",
    "    poem.root = []\n",
    "    poem.children = []\n",
    "\n",
    "    poem.text = soup.find('lg').text\n",
    "    \n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''также мы пробовали pymystem3, однако у него струкутра не такая удобная и тэги не такие понятные и лаконичные'''\n",
    "morph=pymorphy2.MorphAnalyzer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def putShvartsPoemsInMongo(text):\n",
    "    tokenizer = rt('\\w+')\n",
    "    # Загружаем текст стихотворения и прочие элементы\n",
    "    poem = getPoemInfoShvarts(text) \n",
    "    \n",
    "    full_text = {\"meta\": {\"title\": poem.title, \"author\": poem.author, \n",
    "                           \"editors\": poem.editors, \"publishers\":poem.publishers,\n",
    "                           \"edition\":poem.edition, \"date_published\":poem.date_published,\n",
    "                           \"date_written\":poem.date_written}, \n",
    "                \"ID\":poem.ID, \"file\":poem.file, \"root\":poem.root, \"children\":poem.children, \n",
    "                 \"title\": poem.title, \"poem_text\": poem.text}\n",
    "\n",
    "    text_id = collection_60.insert_one(full_text).inserted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''На этом моменте мы кладем в нашу бд все, что у нас имеется'''\n",
    "db['Shvarts_60'].drop()\n",
    "for text in shvarts_60_xml:\n",
    "    putShvartsPoemsInMongo(text)\n",
    "    \n",
    "for text in collection_60.find({'title':{\"$exists\":True}}):\n",
    "    if re.search('_\\d+.xml', text['file']):\n",
    "        changed_duplicate = re.sub('_\\d+.xml', '.xml', text['file'])\n",
    "        collection_60.update_one({'file':changed_duplicate},{'$push':{'children':text['_id']}})\n",
    "        original_poem = collection_60.find({'file' : changed_duplicate}, \n",
    "                                                projection = {'file':True, '_id':True, 'children':True})[0]\n",
    "        \n",
    "        collection_60.update_one({'file':text['file']}, {'$push':{'root':original_poem['_id']}})\n",
    "            \n",
    "            \n",
    "collection_60.create_index([('poem_text', 'text')], default_language='russian')\n",
    "\n",
    "collection_60.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Операция Read - читаем, что у нас в базе данных существует"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_text(where, which):\n",
    "    for text in collection_60.find({where:which}, projection={\"_id\":False, \"poem_text\": True}):\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_text('title','Юродивый')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "duplicates = []\n",
    "for text in collection_60.find({'root': {'$eq':'root'}}, projection={\"_id\":False, \"poem_text\": False}):\n",
    "    duplicates.append(text)\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [title for title in collection_60.find({\"root\": \"root\"}).sort('meta.date_written')]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-080d63d6cf47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection_60\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"$exists\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmeta_for_compare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfile_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_for_compare\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mroots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'root'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'file'"
     ]
    }
   ],
   "source": [
    "file_names = []\n",
    "roots = []\n",
    "for i, element in enumerate(collection_60.find({\"root\": {\"$exists\":True}})):\n",
    "    meta_for_compare = element['meta']\n",
    "    file_names.append(meta_for_compare['file'])\n",
    "    roots.append(element['root'])\n",
    "    \n",
    "for root in roots:\n",
    "    for text in collection_60.find(projection = {'title' : True, 'meta.file': True, 'root':True, \"_id\":False}):\n",
    "        if 'text.meta.file' == root:\n",
    "            print(root)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Операция Update - можем обновить наши данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Например мы видим, что в некоторых местах у нас указание даты написания равно None, а мы уже обрели знание,\n",
    "что текст был написан тогда-то'''\n",
    "\n",
    "collection_60.find_one_and_update({\"meta.title\":\"Об изобретении паровой машины\", \"meta.date_written\":'1967'},{\"$set\":{\"meta.date_written\":1967}}, upsert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in collection_60.find({'meta.title':'Об изобретении паровой машины'}):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(collection, title, name, where, item, for_what):\n",
    "    collection.find_one_and_update({title:name,\n",
    "                                       where:item},\n",
    "                                      {\"$set\":{where:for_what}}, upsert=False)\n",
    "    \n",
    "    for text in collection.find({title:name}):\n",
    "        print(text)\n",
    "    \n",
    "update_data(collection_60, 'meta.title', 'Об изобретении паровой машины',\n",
    "           'meta.date_written', None, 1967)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Операция Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Помним, что там где-то у нас завалялась Агния Львовна - давайте удалим ее, она ж не Шварц'''\n",
    "print(collection_60.count_documents({}))\n",
    "\n",
    "for text in collection_60.find({'TEI.teiHeader.title':'Мишка'}):\n",
    "    print(text)\n",
    "\n",
    "collection_60.delete_many({'TEI.teiHeader.title':'Мишка'})        \n",
    "\n",
    "print(collection_60.count_documents({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort, Regex, Aggregation, полнотекстовый поиск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in collection_60.find({'meta.date_written':{'$gte':1960}}, projection = {'title' : True, 'meta.date_written': True, \"_id\":False}).sort('meta.date_written'):\n",
    "    print(text)\n",
    "# for text in dictionary.find({\"freq\":{\"$gt\": 28}}, {\"token\": True, \"freq\":True, \"_id\":False}).sort(\"freq\"):\n",
    "#     print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RegExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_re(where, word):\n",
    "    for text in collection_60.find({where:{'$regex':'.*'+word+'.*'}}, projection = {'_id':False, 'meta.title':True, 'poem_text':True}):\n",
    "        print(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_re('poem_text','дерев')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles_pipeline = [{\"$unwind\": \"$title\"},\n",
    "            {\"$group\": {\"_id\": \"$title\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
    "           ]\n",
    "pprint = (list(collection_60.aggregate(titles_pipeline)))\n",
    "pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_pipeline_1 = [{\"$unwind\": \"$title\"},\n",
    "            {\"$group\": {\"_id\": \"$title\"}}\n",
    "           ]\n",
    "pprint = (list(collection_60.aggregate(titles_pipeline_1)))\n",
    "\n",
    "titles = [title for title in collection_60.find({\"title\": {\"$exists\": True}}).sort('meta.date_written')]\n",
    "titles = [title for title in collection_60.find({\"root\": None}).sort('meta.date_written')]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_pipeline = [{\"$unwind\": \"$meta.date_published\"},\n",
    "            {\"$group\": {\"_id\": \"$meta.date_published\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
    "           ]\n",
    "pprint.pprint(list(collection_60.aggregate(date_pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Full-text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in collection_60.find({\"$text\": {\"$search\": 'болотами'}}, projection={'_id':False}):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка кода для бэкэнда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_texts = [text for text in collection_60.find({\"poem_text\": {\"$exists\": True}})]\n",
    "for text in poem_text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text():\n",
    "    client = pymongo.MongoClient('mongodb://localhost:27017')\n",
    "    db = client['admin']\n",
    "    collection_60 = db.Shvarts_60\n",
    "    texts = [text for text in collection_60.find({\"poem_text\": {\"$exists\": True}}, \n",
    "                                                 projection={\"_id\":False, \"meta\": False})]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(word):\n",
    "    texts = [text for text in collection_60.find({\"$text\": {\"$search\": word}}, \n",
    "             projection={'_id':False, 'meta':False})]\n",
    "\n",
    "#     poems = []\n",
    "\n",
    "#     for text in texts:\n",
    "#         lst = []\n",
    "#         lst.append(text.get('ID'))\n",
    "#         lst.append(text.get('title'))\n",
    "#         poems.append(lst)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search('дерево')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_texts = [text for text in collection_60.find({\"poem_text\": {\"$exists\": True}}).sort('meta.date_written')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [title for title in collection_60.find({\"title\": {\"$exists\": True}}).sort('meta.date_written')]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [title for title in collection_60.find({\"root\": []}).sort('meta.date_written')]\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
